---
description: View performance metrics and analytics dashboard for features
---

<!--
ATTRIBUTION CHAIN:
1. Original: GitHub spec-kit (https://github.com/github/spec-kit)
   Copyright (c) GitHub, Inc. | MIT License
2. Adapted: SpecKit plugin by Marty Bonacci (2025)
3. Forked: SpecSwarm plugin with tech stack management
   by Marty Bonacci & Claude Code (2025)
4. Enhanced: SpecTest plugin - NEW metrics command
   by Marty Bonacci & Claude Code (2025)
-->

## User Input

```text
$ARGUMENTS
```

Optional: Feature number (e.g., "001") or feature name to view specific metrics.
If not provided, shows summary of all features.

## Overview

The `/spectest:metrics` command displays performance analytics for SpecTest workflow executions, including:
- Time spent per phase (specify, plan, tasks, implement)
- Parallel execution efficiency
- Tech stack violation tracking
- Quality scores
- Comparative analysis across features

## Execution Flow

### 1. Load Metrics Data

```bash
REPO_ROOT=$(git rev-parse --show-toplevel 2>/dev/null || pwd)
METRICS_FILE="${REPO_ROOT}/memory/metrics.json"
```

**If metrics.json does not exist**:
```
ğŸ“Š No metrics data found

Metrics are automatically collected when using SpecTest commands.
Run a feature workflow to start collecting data:

1. /spectest:specify <description>
2. /spectest:plan
3. /spectest:tasks
4. /spectest:implement

Metrics will be saved to /memory/metrics.json
```

**If metrics.json exists**: Proceed to step 2

### 2. Parse User Input

**If $ARGUMENTS is empty**: Show summary dashboard (all features)
**If $ARGUMENTS contains feature number** (e.g., "001"): Show detailed feature metrics
**If $ARGUMENTS contains feature name**: Search for matching feature and show details

### 3. Display Dashboard

#### Option A: Summary Dashboard (No Arguments)

```
ğŸ“Š SpecTest Performance Metrics - Summary

Total Features Tracked: 5
Total Implementation Time: 42m 30s
Average Time per Feature: 8m 30s
Overall Speedup: 2.7x faster (vs sequential)

Recent Features:
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID  â”‚ Feature Name                  â”‚ Duration â”‚ Speedup  â”‚ Status â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 005 â”‚ product-catalog               â”‚ 7m 15s   â”‚ 3.1x     â”‚ âœ“ Done â”‚
â”‚ 004 â”‚ shopping-cart                 â”‚ 9m 42s   â”‚ 2.8x     â”‚ âœ“ Done â”‚
â”‚ 003 â”‚ payment-integration           â”‚ 11m 5s   â”‚ 2.3x     â”‚ âœ“ Done â”‚
â”‚ 002 â”‚ user-profile                  â”‚ 6m 18s   â”‚ 2.9x     â”‚ âœ“ Done â”‚
â”‚ 001 â”‚ user-authentication           â”‚ 8m 10s   â”‚ 2.5x     â”‚ âœ“ Done â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Performance Trends:
â€¢ Average parallel efficiency: 78%
â€¢ Tech stack violations: 0
â€¢ Average quality score: 93/100

View detailed metrics: /spectest:metrics <feature-number>
```

#### Option B: Detailed Feature Metrics (With Feature Number)

```
ğŸ“Š SpecTest Performance Metrics

Feature: 001-user-authentication
Status: âœ“ Completed
Started: 2025-10-11 10:00:00
Completed: 2025-10-11 10:08:10

Phase Breakdown:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase     â”‚ Duration â”‚ Iters   â”‚ Quality Metrics      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Specify   â”‚ 52s      â”‚ 2       â”‚ Score: 95/100        â”‚
â”‚ Plan      â”‚ 95s      â”‚ 1       â”‚ Auto-add: 2 libs     â”‚
â”‚ Tasks     â”‚ 28s      â”‚ 1       â”‚ Parallel: 14 tasks   â”‚
â”‚ Implement â”‚ 315s     â”‚ 1       â”‚ Batches: 3           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Total     â”‚ 8m 10s   â”‚ 5 ops   â”‚ Clean (no errors)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Implementation Details:
â€¢ Total tasks: 26
  - Sequential: 12 tasks (4m 30s)
  - Parallel: 14 tasks in 3 batches (2m 15s)
â€¢ Tech stack compliance: âœ“ No violations
â€¢ Quality checks: âœ“ All passed

Performance Analysis:
â€¢ Actual time: 8m 10s
â€¢ Sequential estimate: 20m 35s
â€¢ Time saved: 12m 25s
â€¢ Speedup factor: 2.5x faster

Parallel Execution Breakdown:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Batch   â”‚ Tasks                     â”‚ Count â”‚ Duration â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Batch 1 â”‚ Models (T003-T008)        â”‚ 6     â”‚ 95s      â”‚
â”‚ Batch 2 â”‚ Services (T011-T016)      â”‚ 5     â”‚ 58s      â”‚
â”‚ Batch 3 â”‚ Tests (T021-T023)         â”‚ 3     â”‚ 42s      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Efficiency: 78% (ideal: 100% linear speedup)

Next Steps:
â€¢ Review implementation: Check modified files
â€¢ Compare with other features: /spectest:metrics
â€¢ Run analyze: /spectest:analyze
```

### 4. Metrics Calculation Logic

**For each phase**: Calculate duration from start_time to end_time
**For implement phase**: Special calculations:
- Sequential time = Sum of all task durations (estimated 5min/task avg)
- Parallel time = Sum of batch durations + sequential task durations
- Time saved = Sequential time - Parallel time
- Speedup factor = Sequential time / Parallel time

**Quality Score** (for specify phase):
```
Score = (100 points) - penalties:
- [NEEDS CLARIFICATION] markers: -5 points each
- Missing mandatory sections: -10 points each
- Incomplete requirements: -3 points each
Minimum score: 0
```

**Parallel Efficiency**:
```
Ideal time = Longest task in batch
Actual time = Batch execution time
Efficiency = (Ideal / Actual) * 100%

Note: 100% = perfect parallelization, <50% = overhead issues
```

### 5. Data Persistence

Metrics are stored in `/memory/metrics.json` with this structure:

```json
{
  "schema_version": "1.0.0",
  "features": {
    "001-user-authentication": {
      "created": "2025-10-11T10:00:00Z",
      "updated": "2025-10-11T10:08:10Z",
      "status": "completed",
      "phases": {
        "specify": {
          "duration_seconds": 52,
          "start_time": "2025-10-11T10:00:00Z",
          "end_time": "2025-10-11T10:00:52Z",
          "iterations": 2,
          "quality_score": 0.95,
          "clarifications": 0
        },
        "plan": {
          "duration_seconds": 95,
          "start_time": "2025-10-11T10:01:00Z",
          "end_time": "2025-10-11T10:02:35Z",
          "iterations": 1,
          "tech_stack_auto_adds": 2,
          "tech_stack_conflicts": 0,
          "tech_stack_violations": 0
        },
        "tasks": {
          "duration_seconds": 28,
          "start_time": "2025-10-11T10:02:40Z",
          "end_time": "2025-10-11T10:03:08Z",
          "total_tasks": 26,
          "parallel_tasks": 14,
          "sequential_tasks": 12
        },
        "implement": {
          "duration_seconds": 315,
          "start_time": "2025-10-11T10:03:15Z",
          "end_time": "2025-10-11T10:08:30Z",
          "parallel_batches": 3,
          "tasks_executed": 26,
          "violations": 0,
          "speedup_factor": 2.5,
          "estimated_sequential_time": 1235,
          "time_saved": 745,
          "batches": [
            {
              "batch_number": 1,
              "tasks": ["T003", "T004", "T005", "T006", "T007", "T008"],
              "duration_seconds": 95
            },
            {
              "batch_number": 2,
              "tasks": ["T011", "T012", "T013", "T014", "T015"],
              "duration_seconds": 58
            },
            {
              "batch_number": 3,
              "tasks": ["T021", "T022", "T023"],
              "duration_seconds": 42
            }
          ]
        }
      },
      "total_duration_seconds": 490
    }
  }
}
```

### 6. Error Handling

**If feature not found**:
```
âŒ Feature not found: {feature_id}

Available features:
- 001-user-authentication
- 002-user-profile
- 003-payment-integration

View all metrics: /spectest:metrics
```

**If metrics incomplete** (feature in progress):
```
âš ï¸ Incomplete metrics for feature: 001-user-authentication

Status: In progress (last phase: tasks)

Completed phases:
âœ“ Specify (52s)
âœ“ Plan (95s)
âœ“ Tasks (28s)
â³ Implement (not started)

Run /spectest:implement to continue
```

## Usage Examples

```bash
# View summary dashboard
/spectest:metrics

# View specific feature by number
/spectest:metrics 001

# View specific feature by partial name
/spectest:metrics user-auth

# After implementing a feature
/spectest:implement
# (automatically saves metrics and displays summary)
```

## Integration Notes

- Metrics are automatically collected by all SpecTest commands
- Pre/post hooks update metrics.json
- No manual configuration required
- Metrics persist across sessions
- Can be exported/analyzed externally (JSON format)

## Comparison with Other Features

When viewing summary dashboard, the command compares:
- Average speedup across features
- Trends in parallel efficiency
- Quality score improvements
- Tech stack violation patterns

This helps identify:
- Which features had best parallel opportunities
- Areas for workflow optimization
- Common bottlenecks
